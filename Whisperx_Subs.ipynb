{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1sH4oRNn2T1S51IeDSSUYliZMyQoi3nBq",
      "authorship_tag": "ABX9TyP0Z8ZSS2GQzwCrb+tIMzCZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KennedyMen/Quickscripts/blob/main/Whisperx_Subs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n",
        "!pip install ffmpeg-python\n",
        "!pip install pysubs2\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "TiSZ4VE3tCDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install ffsubsync\n",
        "!wget https://github.com/kaegi/alass/releases/download/v2.0.0/alass-linux64 -O /usr/local/bin/alass\n",
        "!chmod +x /usr/local/bin/alass\n",
        "\n"
      ],
      "metadata": {
        "id": "RU_HzBpQ7K8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffsubsync --version\n",
        "!python -c \"import faster_whisper; print(faster_whisper.__version__)\"\n",
        "!python -c \"import pysubs2; print(pysubs2.__version__)\"\n",
        "!python -c \"import tqdm; print(tqdm.__version__)\"\n",
        "!ffmpeg -version | head -n 1\n",
        "!alass --version\n"
      ],
      "metadata": {
        "id": "WpVITnR37aZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!alass --version"
      ],
      "metadata": {
        "id": "Z5KNgTs48aoN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import faster_whisper\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "language = \"fr\"\n",
        "input_directory = \"/content/drive/MyDrive/Colab_Notebooks/Files/Media\"  # Change this to your input folder\n",
        "output_directory = \"/content/drive/MyDrive/Colab_Notebooks/Files/Subs\"  # Change this to your output folder\n",
        "\n",
        "# Load Whisper Model\n",
        "model = faster_whisper.WhisperModel(\"large-v2\", device=\"cuda\")\n",
        "\n",
        "def convert_to_hms(seconds: float) -> str:\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    milliseconds = math.floor((seconds % 1) * 1000)\n",
        "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
        "\n",
        "def convert_seg(segment: faster_whisper.transcribe.Segment) -> str:\n",
        "    return f\"{convert_to_hms(segment.start)} --> {convert_to_hms(segment.end)}\\n{segment.text.lstrip()}\\n\\n\"\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Process each audio file in the input directory\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.endswith(\".mp3\") or filename.endswith(\".wav\"):\n",
        "        input_path = os.path.join(input_directory, filename)\n",
        "        output_path = os.path.join(output_directory, f\"{os.path.splitext(filename)[0]}.srt\")\n",
        "\n",
        "        print(f\"Processing: {filename}\")\n",
        "        segments, info = model.transcribe(input_path, language=language)\n",
        "\n",
        "        full_txt = []\n",
        "        timestamps = 0.0  # for progress bar\n",
        "        with tqdm(total=info.duration, unit=\" audio seconds\") as pbar:\n",
        "            for i, segment in enumerate(segments, start=1):\n",
        "                full_txt.append(f\"{i}\\n{convert_seg(segment)}\")\n",
        "                pbar.update(segment.end - timestamps)\n",
        "                timestamps = segment.end\n",
        "            if timestamps < info.duration:  # silence at the end of the audio\n",
        "                pbar.update(info.duration - timestamps)\n",
        "\n",
        "        with open(output_path, mode=\"w\", encoding=\"UTF-8\") as f:\n",
        "            f.writelines(full_txt)\n",
        "        print(f\"Saved: {output_path}\")\n",
        "\n",
        "print(f\"All Subtitles Finished and saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "1l2dpNDYtjUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab_Notebooks/Files/Setup\n",
        "!chmod +x sync_subs.sh\n",
        "!./sync_subs.sh\n"
      ],
      "metadata": {
        "id": "8x2aBe_93tF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import concurrent.futures\n",
        "\n",
        "# Configuration\n",
        "AUDIO_DIRECTORY = \"/content/drive/MyDrive/Colab_Notebooks/Files/Media\"  # Directory containing MP3 files\n",
        "SUBTITLE_DIRECTORY = \"/content/drive/MyDrive/Colab_Notebooks/Files/Subs\"  # Directory containing SRT files\n",
        "OUTPUT_DIRECTORY = \"/content/drive/MyDrive/Colab_Notebooks/Files/Subs\"  # Where to save synced subtitles\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def sync_subtitle(audio_path, srt_path):\n",
        "    \"\"\"\n",
        "    Sync subtitle file using ffsubsync first, then use that output with alass\n",
        "    Returns the path to the final synchronized subtitle file\n",
        "    \"\"\"\n",
        "    output_dir = Path(OUTPUT_DIRECTORY)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    base_name = Path(srt_path).stem\n",
        "    temp_ffsubsync_output = output_dir / f\"{base_name}_ffsubsync_temp.srt\"\n",
        "    final_output = output_dir / f\"{base_name}_synced.srt\"\n",
        "\n",
        "    try:\n",
        "        # Step 1: FFSubsync\n",
        "        logger.info(f\"Running ffsubsync on {srt_path}\")\n",
        "        subprocess.run([\n",
        "            \"ffsubsync\",\n",
        "            str(audio_path),\n",
        "            \"-i\", str(srt_path),\n",
        "            \"-o\", str(temp_ffsubsync_output)\n",
        "        ], check=True, capture_output=True)\n",
        "\n",
        "        # Step 2: Alass (using ffsubsync output as input)\n",
        "        if temp_ffsubsync_output.exists():\n",
        "            logger.info(f\"Running alass on ffsubsync output\")\n",
        "            subprocess.run([\n",
        "                \"alass\",\n",
        "                str(audio_path),\n",
        "                str(temp_ffsubsync_output),\n",
        "                str(final_output)\n",
        "            ], check=True, capture_output=True)\n",
        "\n",
        "            # Clean up temporary file\n",
        "            temp_ffsubsync_output.unlink()\n",
        "\n",
        "            if final_output.exists():\n",
        "                logger.info(f\"Successfully created synced version for {base_name}\")\n",
        "                return final_output\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        logger.error(f\"Error syncing {srt_path}: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unexpected error processing {srt_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "def find_matching_pairs():\n",
        "    \"\"\"\n",
        "    Find matching audio and subtitle files across the two directories\n",
        "    \"\"\"\n",
        "    audio_files = {f.stem: f for f in Path(AUDIO_DIRECTORY).glob(\"*.mp3\")}\n",
        "    srt_files = {f.stem: f for f in Path(SUBTITLE_DIRECTORY).glob(\"*.srt\")}\n",
        "\n",
        "    pairs = []\n",
        "    for name in audio_files.keys() & srt_files.keys():  # Intersection of filenames\n",
        "        pairs.append((audio_files[name], srt_files[name]))\n",
        "\n",
        "    return pairs\n",
        "\n",
        "def main():\n",
        "    # Validate directories\n",
        "    for directory in [AUDIO_DIRECTORY, SUBTITLE_DIRECTORY]:\n",
        "        if not os.path.exists(directory):\n",
        "            logger.error(f\"Directory does not exist: {directory}\")\n",
        "            return\n",
        "\n",
        "    pairs = find_matching_pairs()\n",
        "    if not pairs:\n",
        "        logger.warning(\"No matching audio/subtitle pairs found!\")\n",
        "        logger.info(f\"Audio files: {list(Path(AUDIO_DIRECTORY).glob('*.mp3'))}\")\n",
        "        logger.info(f\"Subtitle files: {list(Path(SUBTITLE_DIRECTORY).glob('*.srt'))}\")\n",
        "        return\n",
        "\n",
        "    logger.info(f\"Found {len(pairs)} matching pairs to process\")\n",
        "\n",
        "    # Process files in parallel\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        future_to_pair = {\n",
        "            executor.submit(sync_subtitle, audio, srt): (audio, srt)\n",
        "            for audio, srt in pairs\n",
        "        }\n",
        "\n",
        "        for future in concurrent.futures.as_completed(future_to_pair):\n",
        "            audio, srt = future_to_pair[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                if result:\n",
        "                    logger.info(f\"Successfully processed {srt.name}\")\n",
        "                else:\n",
        "                    logger.error(f\"Failed to process {srt.name}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing {srt.name}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "XiBjxt9pGQUC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep ffsubsync\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djRGKqJsA5el",
        "outputId": "c2446b5b-c0d5-463d-8753-459e380f7340"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        3142  0.0  0.0   6484  2240 ?        S    20:46   0:00 grep ffsubsync\n"
          ]
        }
      ]
    }
  ]
}